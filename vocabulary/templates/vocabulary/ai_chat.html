{% extends 'vocabulary/base.html' %}

{% block content %}
<!-- Load Tailwind CSS for this page specifically to match the React design -->
<script src="https://cdn.tailwindcss.com"></script>
<script>
    tailwind.config = {
        theme: {
            extend: {
                fontFamily: {
                    sans: ['Inter', 'sans-serif'],
                },
                animation: {
                    'pulse-slow': 'pulse 3s cubic-bezier(0.4, 0, 0.6, 1) infinite',
                }
            }
        }
    }
</script>
<!-- Import Map for Google GenAI SDK -->
<script type="importmap">
  {
    "imports": {
      "@google/genai": "https://esm.run/@google/genai"
    }
  }
</script>

<div class="h-[calc(100vh-60px)] bg-slate-50 flex flex-col font-sans text-slate-900 overflow-hidden relative">

    <!-- Config Bar (Added Feature) -->
    <div id="config-bar" class="bg-slate-800 text-white px-4 py-2 text-xs flex flex-wrap gap-3 items-center justify-between shadow-md z-30">
        <div class="flex items-center gap-2 flex-1 min-w-[200px]">
            <span class="font-bold text-slate-400">API KEY:</span>
            <input type="password" id="api-key-input" class="bg-slate-700 border-none rounded px-2 py-1 text-white w-full focus:ring-1 focus:ring-blue-500 outline-none" placeholder="AIzaSy..." value="AIzaSyDWAwj87eZR1sfVby8oidPw_jRqYv-sa_w">
        </div>
        <div class="flex items-center gap-2 flex-1 min-w-[200px]">
            <span class="font-bold text-slate-400">MODEL:</span>
            <input type="text" id="model-input" class="bg-slate-700 border-none rounded px-2 py-1 text-white w-full focus:ring-1 focus:ring-blue-500 outline-none" placeholder="models/gemini-..." value="gemini-2.0-flash-exp">
        </div>
        <button id="update-config-btn" class="bg-blue-600 hover:bg-blue-500 text-white px-3 py-1 rounded font-bold transition-colors">
            Yangilash
        </button>
    </div>

    <!-- Header (Similar to App.tsx Navbar) -->
    <nav class="bg-white border-b border-slate-200 px-4 py-3 flex items-center justify-between shrink-0 shadow-sm z-20">
        <div class="flex items-center gap-3">
          <div class="w-10 h-10 bg-red-500 rounded-xl flex items-center justify-center text-white font-bold text-xl shadow-sm">
            あ
          </div>
          <div>
            <h1 class="text-lg font-black tracking-tight text-slate-800 leading-none">EasyNihongo</h1>
            <span class="text-[9px] font-bold text-slate-400 uppercase tracking-widest">Live Japanese Tutor</span>
          </div>
        </div>

        <div class="flex items-center gap-2 bg-slate-50 px-3 py-1.5 rounded-full border border-slate-200">
          <div id="status-dot" class="w-2 h-2 rounded-full bg-slate-300"></div>
          <span id="status-text" class="text-[10px] font-bold text-slate-600 uppercase">OFFLINE</span>
        </div>
    </nav>

    <!-- Main Chat Area -->
    <main class="flex-1 flex flex-col max-w-2xl w-full mx-auto overflow-hidden relative p-3 md:p-4 gap-3">

        <!-- Error Overlay -->
        <div id="error-box" class="hidden bg-red-50 border border-red-200 p-3 rounded-xl flex items-center gap-3 animate-bounce z-30 shrink-0">
            <p id="error-msg" class="text-red-800 font-bold text-xs flex-1"></p>
            <button onclick="document.getElementById('error-box').classList.add('hidden')" class="text-red-400">
              <svg class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" /></svg>
            </button>
        </div>

        <!-- Chat History -->
        <div id="chat-history" class="flex-1 bg-white rounded-[1.5rem] border border-slate-200 shadow-sm overflow-y-auto px-4 py-5 space-y-4 scroll-smooth">
            <!-- Initial Empty State -->
            <div id="empty-state" class="h-full flex flex-col items-center justify-center text-center px-6">
                <div class="w-20 h-20 bg-slate-50 rounded-full flex items-center justify-center mb-4 border border-dashed border-slate-200">
                    <svg class="w-8 h-8 text-slate-200" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-5l-5 5v-5z" /></svg>
                </div>
                <p class="text-slate-400 text-sm font-medium">Sensei bilan suhbatni boshlang...</p>
            </div>

            <!-- Messages Container -->
            <div id="messages-list" class="flex flex-col gap-4 hidden"></div>
        </div>

        <!-- Visualizer Area -->
        <div class="shrink-0 h-[60px] relative">
            <canvas id="visualizer-canvas" class="w-full h-full rounded-2xl bg-white/50 border border-slate-100 backdrop-blur-sm hidden"></canvas>
        </div>

        <!-- Controls -->
        <div class="shrink-0 pb-2">
            <!-- Start Button -->
            <button id="start-btn" class="w-full h-16 rounded-2xl bg-slate-900 text-white font-bold text-lg shadow-xl active:scale-[0.98] transition-all flex items-center justify-center gap-3 hover:bg-slate-800">
                <div class="w-8 h-8 bg-red-500 rounded-lg flex items-center justify-center">
                    <svg class="w-4 h-4 fill-current ml-0.5" viewBox="0 0 24 24"><path d="M8 5v14l11-7z"/></svg>
                </div>
                <span>Darsni Boshlash</span>
            </button>

            <!-- Stop/Listening State (Hidden by default) -->
            <div id="active-controls" class="hidden flex flex-col gap-2">
                <button id="stop-btn" class="w-full h-16 bg-white border border-slate-200 text-slate-800 rounded-2xl font-bold text-lg hover:bg-slate-50 active:scale-[0.98] transition-all flex items-center justify-center gap-3 shadow-sm">
                    <div class="w-3 h-3 bg-red-500 rounded-sm"></div>
                    Darsni Tugatish
                </button>
                <p class="text-center text-slate-400 text-[9px] font-bold uppercase tracking-[0.2em] animate-pulse">
                    Sensei eshitmoqda...
                </p>
            </div>
        </div>
    </main>
</div>

<!-- Logic Script -->
<script type="module">
    import { GoogleGenAI } from "@google/genai";

    // --- State Management ---
    const state = {
        apiKey: document.getElementById('api-key-input').value,
        modelName: document.getElementById('model-input').value,
        isConnected: false,
        isModelSpeaking: false,
        messages: [],
        session: null,
        client: null,
        audioContext: null,
        stream: null,
        processor: null,
        source: null,
        playbackNextStartTime: 0
    };

    const SYSTEM_INSTRUCTION = `
Siz "EasyNihongo Sensei" ismli, o'ta sabrli va do'stona yapon tili o'qituvchisisiz. Sizning talabalaringiz asosan o'zbek tilida so'zlashuvchi N5/N4 darajasidagi boshlovchilardir.

ASOSIY QOIDALAR:
1. TILINGIZ: Asosan oddiy yapon tilida gapiring (Desu/Masu formasi). O'zbek tilidan faqat tushunarsiz joylarni izohlash, xatolarni tuzatish yoki talaba tushunmay qolganida "ko'prik" sifatida foydalaning.
2. ROMAJI (MUHIM): Talaba hali iyeroglif va xiraganani yaxshi bilmasligi mumkin. Shuning uchun, HAR BIR yaponcha gapdan keyin qavs ichida uning o'qilishini (Romaji - lotin harflarida) yozib keting.
   Misol: こんにちは (Konnichiwa).
3. QISQA JAVOBLAR: Ovozli interfeys bo'lgani uchun javoblaringiz 2-3 gapdan oshmasin.
4. XATOLARNI TUZATISH: Agar talaba xato qilsa, avval to'g'ri variantni yaponcha ayting, keyin o'zbek tilida 1 jumlada nima uchun bundayligini tushuntiring.
5. SUHBATNI DAVOM ETTIRISH: Har doim gapingiz oxirida talabaga javob berish oson bo'lgan qisqa savol bering.
`;

    // --- DOM Elements ---
    const els = {
        startBtn: document.getElementById('start-btn'),
        activeControls: document.getElementById('active-controls'),
        stopBtn: document.getElementById('stop-btn'),
        statusDot: document.getElementById('status-dot'),
        statusText: document.getElementById('status-text'),
        chatHistory: document.getElementById('chat-history'),
        messagesList: document.getElementById('messages-list'),
        emptyState: document.getElementById('empty-state'),
        errorBox: document.getElementById('error-box'),
        errorMsg: document.getElementById('error-msg'),
        canvas: document.getElementById('visualizer-canvas'),
        updateConfigBtn: document.getElementById('update-config-btn'),
        apiKeyInput: document.getElementById('api-key-input'),
        modelInput: document.getElementById('model-input')
    };

    // --- Config Handlers ---
    els.updateConfigBtn.addEventListener('click', () => {
        state.apiKey = els.apiKeyInput.value;
        state.modelName = els.modelInput.value;
        alert("Sozlamalar yangilandi! Endi 'Darsni Boshlash' tugmasini bosing.");
        if(state.isConnected) stopConversation();
    });

    // --- Chat Logic ---
    els.startBtn.addEventListener('click', startConversation);
    els.stopBtn.addEventListener('click', stopConversation);

    async function startConversation() {
        if (!state.apiKey) {
            showError("API kalit kiritilmagan!");
            return;
        }

        try {
            setLoading(true);
            showError(null); // Clear errors

            // 1. Init Client
            const client = new GoogleGenAI({ apiKey: state.apiKey });

            // 2. Audio Context
            state.audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });

            // 3. Mic Access
            state.stream = await navigator.mediaDevices.getUserMedia({
                audio: { channelCount: 1, sampleRate: 16000 }
            });

            // 4. Connect Config
            const config = {
                model: state.modelName, // Dynamic model name
                config: {
                    responseModalities: ["AUDIO"],
                    speechConfig: {
                        voiceConfig: { prebuiltVoiceConfig: { voiceName: "Aoede" } }
                    },
                    systemInstruction: { parts: [{ text: SYSTEM_INSTRUCTION }] },
                },
            };

            // 5. Connect
            state.session = await client.live.connect(config);

            // 6. Setup Listeners
            // Note: The SDK might change. Using 'on' if available or fallback.
            // But based on provided v1.4 code, we wrap handlers differently?
            // Actually, the new SDK returns a session object with `sendRealtimeInput` and emits events.
            // Let's attach generic listeners via direct internal handling or documentation standard.
            // Since `client.live.connect` returns a session, we listen to its stream.

            // IMPORTANT: The previous SDK code used callbacks in config.
            // Let's try the modern stream iteration approach or the callback config approach.
            // Based on previous success, let's use the CALLBACK approach passed to `connect` if supported,
            // OR iterate the incoming stream.
            // But wait, the previous code passed `callbacks` in `config`. Let's do that.

            // Re-creating config with callbacks
            const configWithCallbacks = {
                ...config,
                callbacks: {
                    onmessage: (msg) => handleServerMessage(msg),
                    onError: (err) => {
                        console.error("Session Error:", err);
                        showError("Ulanish xatosi: " + (err.message || "Noma'lum"));
                        stopConversation();
                    },
                    onClose: (evt) => {
                        console.log("Session Closed", evt);
                        stopConversation();
                    }
                }
            };

            // Re-connect with callbacks
            state.session = await client.live.connect(configWithCallbacks);

            // 7. Setup Input Processing
            state.source = state.audioContext.createMediaStreamSource(state.stream);
            state.processor = state.audioContext.createScriptProcessor(4096, 1, 1);

            state.processor.onaudioprocess = (e) => {
                if (!state.session || !state.isConnected) return;
                try {
                    const inputData = e.inputBuffer.getChannelData(0);
                    const b64Data = floatTo16BitPCM(inputData);
                    state.session.sendRealtimeInput({
                        media: { mimeType: "audio/pcm;rate=16000", data: b64Data }
                    });
                } catch(err) {
                     // Ignore send errors on closing
                }
            };

            state.source.connect(state.processor);
            state.processor.connect(state.audioContext.destination);

            // Success
            state.isConnected = true;
            updateUI(true);
            visualizeAudio(true);

        } catch (e) {
            console.error(e);
            showError("Ulanishda xatolik: " + e.message + " (Model nomini tekshiring)");
            setLoading(false);
            stopConversation();
        }
    }

    function stopConversation() {
        state.isConnected = false;

        if (state.processor) {
            state.processor.disconnect();
            state.processor.onaudioprocess = null;
            state.processor = null;
        }
        if (state.source) { state.source.disconnect(); state.source = null; }
        if (state.stream) { state.stream.getTracks().forEach(t => t.stop()); state.stream = null; }
        if (state.session) {
            try { state.session.close(); } catch(e){}
            state.session = null;
        }
        if (state.audioContext) {
            try { state.audioContext.close(); } catch(e){}
            state.audioContext = null;
        }

        updateUI(false);
    }

    // --- Message Handling ---
    async function handleServerMessage(message) {
        // Audio
        if (message.serverContent?.modelTurn?.parts) {
            for (const part of message.serverContent.modelTurn.parts) {
                if (part.inlineData?.data) {
                    playAudioChunk(part.inlineData.data);
                }
                // Check for text transcriptions if available in future
            }
        }

        // Turn handling logic (optional)
        if (message.serverContent?.turnComplete) {
            state.isModelSpeaking = false;
        }
    }

    async function playAudioChunk(base64Data) {
        if (!state.audioContext) return;
        try {
            const arrayBuffer = base64ToArrayBuffer(base64Data);

            // Convert raw PCM to WAV container so decodeAudioData can understand it
            // Gemini typically returns 24000Hz mono PCM
            const wavBuffer = pcmToWav(arrayBuffer, 24000);

            const audioBuffer = await state.audioContext.decodeAudioData(wavBuffer);

            const source = state.audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(state.audioContext.destination);

            const now = state.audioContext.currentTime;
            const startTime = Math.max(now, state.playbackNextStartTime);
            source.start(startTime);
            state.playbackNextStartTime = startTime + audioBuffer.duration;

            state.isModelSpeaking = true;

            // Simple visualizer trigger
            source.onended = () => {
                if (state.audioContext && state.audioContext.currentTime >= state.playbackNextStartTime) {
                    state.isModelSpeaking = false;
                }
            };
        } catch (e) { console.error(e); }
    }

    // --- UI Helpers ---
    function updateUI(connected) {
        if (connected) {
            els.startBtn.classList.add('hidden');
            els.activeControls.classList.remove('hidden');
            els.statusDot.className = "w-2 h-2 rounded-full bg-green-500 animate-pulse";
            els.statusText.innerText = "ONLINE";
            els.canvas.classList.remove('hidden');
            // Hide empty state if we wanted, but let's keep it until messages appear
            els.emptyState.innerHTML = '<p class="text-slate-400 text-sm">Suhbat boshlandi...</p>';
        } else {
            els.startBtn.classList.remove('hidden');
            els.activeControls.classList.add('hidden');
            els.statusDot.className = "w-2 h-2 rounded-full bg-slate-300";
            els.statusText.innerText = "OFFLINE";
            els.canvas.classList.add('hidden');
            setLoading(false);
        }
    }

    function setLoading(isLoading) {
        if (isLoading) {
            els.startBtn.disabled = true;
            els.startBtn.innerHTML = '<div class="w-5 h-5 border-2 border-white/20 border-t-white rounded-full animate-spin"></div><span>Ulanmoqda...</span>';
        } else {
            els.startBtn.disabled = false;
            els.startBtn.innerHTML = '<div class="w-8 h-8 bg-red-500 rounded-lg flex items-center justify-center"><svg class="w-4 h-4 fill-current ml-0.5" viewBox="0 0 24 24"><path d="M8 5v14l11-7z"/></svg></div><span>Darsni Boshlash</span>';
        }
    }

    function showError(msg) {
        if (msg) {
            els.errorBox.classList.remove('hidden');
            els.errorMsg.innerText = msg;
        } else {
            els.errorBox.classList.add('hidden');
        }
    }

    // --- Audio Utils ---
    function floatTo16BitPCM(input) {
        let output = new Int16Array(input.length);
        for (let i = 0; i < input.length; i++) {
            let s = Math.max(-1, Math.min(1, input[i]));
            output[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }
        const bytes = new Uint8Array(output.buffer);
        let binary = '';
        for (let i = 0; i < bytes.byteLength; i++) {
             binary += String.fromCharCode(bytes[i]);
        }
        return btoa(binary);
    }

    function base64ToArrayBuffer(base64) {
        const binaryString = atob(base64);
        const bytes = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
            bytes[i] = binaryString.charCodeAt(i);
        }
        return bytes.buffer;
    }

    function pcmToWav(pcmData, sampleRate = 24000) {
        // pcmData is an ArrayBuffer containing raw 16-bit PCM data
        const numChannels = 1;
        const bitsPerSample = 16;
        const byteRate = (sampleRate * numChannels * bitsPerSample) / 8;
        const blockAlign = (numChannels * bitsPerSample) / 8;
        const dataSize = pcmData.byteLength;
        const buffer = new ArrayBuffer(44 + dataSize);
        const view = new DataView(buffer);

        // RIFF chunk descriptor
        writeString(view, 0, 'RIFF');
        view.setUint32(4, 36 + dataSize, true);
        writeString(view, 8, 'WAVE');

        // fmt sub-chunk
        writeString(view, 12, 'fmt ');
        view.setUint32(16, 16, true); // Subchunk1Size (16 for PCM)
        view.setUint16(20, 1, true); // AudioFormat (1 for PCM)
        view.setUint16(22, numChannels, true); // NumChannels
        view.setUint32(24, sampleRate, true); // SampleRate
        view.setUint32(28, byteRate, true); // ByteRate
        view.setUint16(32, blockAlign, true); // BlockAlign
        view.setUint16(34, bitsPerSample, true); // BitsPerSample

        // data sub-chunk
        writeString(view, 36, 'data');
        view.setUint32(40, dataSize, true);

        // Write PCM data
        const pcmBytes = new Uint8Array(pcmData);
        const wavBytes = new Uint8Array(buffer, 44);
        wavBytes.set(pcmBytes);

        return buffer;
    }

    function writeString(view, offset, string) {
        for (let i = 0; i < string.length; i++) {
            view.setUint8(offset + i, string.charCodeAt(i));
        }
    }

    // Expose for testing
    window.pcmToWav = pcmToWav;

    // --- Visualizer ---
    function visualizeAudio() {
        if (!state.isConnected) return;

        const canvas = els.canvas;
        const ctx = canvas.getContext("2d");
        const width = canvas.width = canvas.offsetWidth;
        const height = canvas.height = canvas.offsetHeight;

        ctx.clearRect(0, 0, width, height);

        // Draw bars
        const bars = 30;
        const barWidth = width / bars;

        ctx.fillStyle = state.isModelSpeaking ? "#ef4444" : "#94a3b8"; // Red if model speaks, gray if user listening

        for (let i = 0; i < bars; i++) {
            // Random height for demo, real implementation would use AnalyzerNode
            const h = Math.random() * (state.isModelSpeaking ? height * 0.8 : height * 0.3);
            const x = i * barWidth;
            const y = (height - h) / 2;

            // Rounded bars
            ctx.beginPath();
            ctx.roundRect(x + 2, y, barWidth - 4, h, 4);
            ctx.fill();
        }

        requestAnimationFrame(visualizeAudio);
    }

    console.log("EasyNihongo AI Module Ready (v2.0 Configurable)");
</script>

{% endblock %}

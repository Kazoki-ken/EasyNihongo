{% extends 'vocabulary/base.html' %}

{% block content %}
<div class="container-fluid p-0">
    <div id="ai-chat-app" class="h-100 d-flex flex-col">
        <!-- Chat Interface will be injected here -->
        <div class="text-center p-5">
            <div class="spinner-border text-primary" role="status">
                <span class="visually-hidden">Loading...</span>
            </div>
            <p class="mt-3 text-muted">AI O'qituvchi yuklanmoqda... (v1.3 Debug)</p>
        </div>
    </div>
</div>

<style>
    /* Chat Specific Styles to override/complement base.html */
    .chat-container {
        height: calc(100vh - 80px); /* Adjusted height calculation */
        display: flex;
        flex-direction: column;
        background-color: #f8f9fa;
        max-width: 800px; /* Center on PC */
        margin: 0 auto;
        border-left: 1px solid #eee;
        border-right: 1px solid #eee;
        position: relative; /* Ensure stacking context */
    }

    body.dark-mode .chat-container {
        background-color: #121212;
        border-color: #333;
    }

    .chat-messages {
        flex: 1;
        overflow-y: auto;
        padding: 20px;
        display: flex;
        flex-direction: column;
        gap: 15px;
        /* Ensure it doesn't get hidden behind controls */
        margin-bottom: 0;
    }

    .chat-bubble {
        max-width: 80%;
        padding: 12px 16px;
        border-radius: 18px;
        font-size: 0.95rem;
        line-height: 1.5;
        position: relative;
    }

    .chat-bubble.user {
        align-self: flex-end;
        background-color: #0d6efd;
        color: white;
        border-bottom-right-radius: 4px;
    }

    .chat-bubble.model {
        align-self: flex-start;
        background-color: white;
        color: #333;
        border: 1px solid #e0e0e0;
        border-bottom-left-radius: 4px;
    }

    body.dark-mode .chat-bubble.model {
        background-color: #2c2c2c;
        color: #e0e0e0;
        border-color: #444;
    }

    .japanese-text {
        font-family: 'Noto Sans JP', sans-serif;
    }

    .controls-area {
        padding: 15px;
        background: white;
        border-top: 1px solid #eee;
        display: flex;
        flex-direction: column;
        gap: 10px;
        align-items: center;
    }

    body.dark-mode .controls-area {
        background: #1e1e1e;
        border-color: #333;
    }

    .mic-btn {
        width: 70px;
        height: 70px;
        border-radius: 50%;
        border: none;
        background: #ff6b81; /* Sakura Red */
        color: white;
        font-size: 1.8rem;
        box-shadow: 0 4px 15px rgba(255, 107, 129, 0.4);
        transition: all 0.2s ease;
        display: flex;
        align-items: center;
        justify-content: center;
    }

    .mic-btn:active {
        transform: scale(0.95);
    }

    .mic-btn.listening {
        background: #dc3545;
        animation: pulse 1.5s infinite;
    }

    .mic-btn:disabled {
        background: #ccc;
        box-shadow: none;
    }

    @keyframes pulse {
        0% { box-shadow: 0 0 0 0 rgba(220, 53, 69, 0.7); }
        70% { box-shadow: 0 0 0 15px rgba(220, 53, 69, 0); }
        100% { box-shadow: 0 0 0 0 rgba(220, 53, 69, 0); }
    }

    .status-text {
        font-size: 0.8rem;
        color: #999;
        font-weight: 600;
        text-transform: uppercase;
        letter-spacing: 1px;
    }

    canvas#visualizer {
        width: 100%;
        height: 60px;
        border-radius: 10px;
        background: rgba(0,0,0,0.02);
    }

    body.dark-mode canvas#visualizer {
        background: rgba(255,255,255,0.05);
    }

    /* Debug Console in UI */
    #debug-console {
        font-size: 0.7rem;
        color: #dc3545;
        max-height: 60px;
        overflow-y: auto;
        width: 100%;
        text-align: center;
        margin-top: 5px;
        display: none;
    }

</style>

<!-- Load Google Generative AI SDK via Import Map for better compatibility -->
<script type="importmap">
  {
    "imports": {
      "@google/genai": "https://esm.run/@google/genai"
    }
  }
</script>

<script type="module">
    import { GoogleGenAI } from "@google/genai";

    console.log("AI Chat Module Loaded - v1.4 (CrashFix)");

    // --- CONFIGURATION ---
    // TODO: For production, move this key to the backend/environment variables
    const API_KEY = "AIzaSyAwlNzbGNZ_BzCqsLsDMhFiP1DsEz0Ak44";
    const SYSTEM_INSTRUCTION = `
Siz "EasyNihongo Sensei" ismli, o'ta sabrli va do'stona yapon tili o'qituvchisisiz. Sizning talabalaringiz asosan o'zbek tilida so'zlashuvchi N5/N4 darajasidagi boshlovchilardir.

ASOSIY QOIDALAR:
1. TILINGIZ: Asosan oddiy yapon tilida gapiring (Desu/Masu formasi). O'zbek tilidan faqat tushunarsiz joylarni izohlash, xatolarni tuzatish yoki talaba tushunmay qolganida "ko'prik" sifatida foydalaning.
2. ROMAJI (MUHIM): Talaba hali iyeroglif va xiraganani yaxshi bilmasligi mumkin. Shuning uchun, HAR BIR yaponcha gapdan keyin qavs ichida uning o'qilishini (Romaji - lotin harflarida) yozib keting.
   Misol: こんにちは (Konnichiwa).
3. QISQA JAVOBLAR: Ovozli interfeys bo'lgani uchun javoblaringiz 2-3 gapdan oshmasin.
4. XATOLARNI TUZATISH: Agar talaba xato qilsa, avval to'g'ri variantni yaponcha ayting, keyin o'zbek tilida 1 jumlada nima uchun bundayligini tushuntiring.
5. SUHBATNI DAVOM ETTIRISH: Har doim gapingiz oxirida talabaga javob berish oson bo'lgan qisqa savol bering.

MULOQOT STRATEGIYASI:
- Agar talaba jim bo'lib qolsa, oddiy mavzularni taklif qiling: oila, sevimli ovqatlar, ob-havo yoki yapon madaniyati.
- Talabani har bir to'g'ri aytilgan so'z uchun maqtang (Sugoi desu ne!, Jozu desu ne!).
- Murakkab grammatik terminlarni ishlatmang, sodda tushuntiring.
`;

    // --- DOM ELEMENTS ---
    const appContainer = document.getElementById('ai-chat-app');

    // --- STATE ---
    let client = null;
    let session = null;
    let isConnected = false;
    let audioContext = null;
    let stream = null;
    let processor = null;
    let source = null;
    let playbackNextStartTime = 0; // For queueing audio

    // UI BUILDER
    function renderUI() {
        appContainer.innerHTML = `
            <div class="chat-container">
                <div class="d-flex align-items-center justify-content-between px-3 py-2 bg-white border-bottom shadow-sm app-header">
                    <div class="d-flex align-items-center">
                         <div class="rounded-circle d-flex align-items-center justify-content-center me-2 bg-danger text-white fw-bold" style="width: 40px; height: 40px;">先</div>
                         <div>
                            <h6 class="mb-0 fw-bold">Sensei AI</h6>
                            <span class="text-muted" style="font-size: 0.7rem;">Beta v1.3</span>
                         </div>
                    </div>
                    <div id="status-indicator" class="badge bg-secondary">OFFLINE</div>
                </div>

                <div id="messages-area" class="chat-messages">
                    <div class="text-center text-muted mt-5">
                        <i class="bi bi-mic fs-1 d-block mb-3 opacity-50"></i>
                        <p>Mikrofon tugmasini bosing va Sensei bilan gaplashing!</p>
                    </div>
                </div>

                <div class="controls-area">
                    <canvas id="visualizer"></canvas>
                    <div id="debug-console"></div>
                    <button id="mic-btn" class="mic-btn">
                        <i class="bi bi-mic-fill"></i>
                    </button>
                    <p id="status-text" class="status-text mt-2">Darsni Boshlash</p>
                </div>
            </div>
        `;

        document.getElementById('mic-btn').addEventListener('click', toggleConnection);
    }

    function logError(msg) {
        const consoleEl = document.getElementById('debug-console');
        if (consoleEl) {
            consoleEl.style.display = 'block';
            consoleEl.innerText = msg;
        }
        console.error(msg);
    }

    // --- LOGIC ---
    async function toggleConnection() {
        if (isConnected) {
            await disconnect();
        } else {
            await connect();
        }
    }

    async function connect() {
        const statusEl = document.getElementById('status-indicator');
        const btn = document.getElementById('mic-btn');
        const statusText = document.getElementById('status-text');
        const debugEl = document.getElementById('debug-console');

        // Reset debug
        if(debugEl) debugEl.style.display = 'none';

        try {
            statusText.innerText = "Ulanmoqda...";
            btn.disabled = true;

            // 1. Init Client
            const client = new GoogleGenAI({ apiKey: API_KEY });

            // 2. Audio Context (Input & Output)
            audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });

            // 3. Microphone Access
            stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    channelCount: 1,
                    sampleRate: 16000
                }
            });

            // 4. Connect to Gemini Live API
            console.log("Connecting to Gemini Live...");

            // Define config
            const config = {
                // User requested 'gemini-2.5-flash-native-audio', but sticking to 'gemini-2.0-flash-exp' for public API compatibility.
                // If you have access to 2.5 via this key, you can uncomment the line below:
                // model: "gemini-2.5-flash-native-audio",
                model: "gemini-2.0-flash-exp",
                config: {
                    responseModalities: ["AUDIO"],
                    speechConfig: {
                        voiceConfig: { prebuiltVoiceConfig: { voiceName: "Aoede" } }
                    },
                    systemInstruction: { parts: [{ text: SYSTEM_INSTRUCTION }] },
                },
                // Callbacks for events
                callbacks: {
                    onmessage: (message) => {
                        handleServerMessage(message);
                    },
                    onError: (err) => {
                        logError("Session Error: " + (err.message || JSON.stringify(err)));
                        disconnect(); // Force disconnect on error
                    },
                    onClose: (event) => {
                        logError("Session Closed: " + (event.reason || "Connection lost"));
                        disconnect();
                    }
                }
            };

            session = await client.live.connect(config);

            // 5. Setup Input Stream (Send Audio)
            source = audioContext.createMediaStreamSource(stream);
            processor = audioContext.createScriptProcessor(4096, 1, 1);

            processor.onaudioprocess = (e) => {
                // Critical Check: ensure session is open and connected
                if (!session || !isConnected) return;

                try {
                    const inputData = e.inputBuffer.getChannelData(0);
                    const b64Data = floatTo16BitPCM(inputData);

                    // Double check before sending
                    if(isConnected) {
                        session.sendRealtimeInput({
                            media: {
                                mimeType: "audio/pcm;rate=16000",
                                data: b64Data
                            }
                        });
                    }
                } catch(err) {
                    // Filter out expected errors when closing
                    if (err.message && (err.message.includes("CLOSING") || err.message.includes("CLOSED"))) {
                        // socket closed, stop trying
                        console.warn("Socket closed during send, disconnecting...");
                        disconnect();
                    } else {
                        console.error("Send Error:", err);
                    }
                }
            };

            source.connect(processor);
            processor.connect(audioContext.destination);

            isConnected = true;
            updateUIState(true);

        } catch (e) {
            console.error("Connection failed:", e);
            logError("Ulanish xatosi: " + e.message);
            await disconnect();
        }
    }

    // Updated: Handle Incoming Messages via Callback
    async function handleServerMessage(message) {
        // 1. Check for standard 'serverContent' with 'modelTurn' (Multimodal API)
        if (message.serverContent && message.serverContent.modelTurn && message.serverContent.modelTurn.parts) {
            for (const part of message.serverContent.modelTurn.parts) {
                if (part.inlineData && part.inlineData.data) {
                    playAudioChunk(part.inlineData.data);
                }
            }
        }
    }

    async function playAudioChunk(base64Data) {
        if (!audioContext) return;

        try {
            const audioData = base64ToArrayBuffer(base64Data);
            const audioBuffer = await audioContext.decodeAudioData(audioData);

            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);

            const now = audioContext.currentTime;
            // Ensure smooth playback sequence
            const startTime = Math.max(now, playbackNextStartTime);
            source.start(startTime);
            playbackNextStartTime = startTime + audioBuffer.duration;

            // Visualize (simple trigger)
            visualizeAudio(true);

        } catch (e) {
            console.error("Audio decode error:", e);
        }
    }

    async function disconnect() {
        // 1. Immediately flag as disconnected to stop loops
        isConnected = false;
        updateUIState(false);

        // 2. Stop Processor first (stop sending data)
        if (processor) {
            processor.disconnect();
            processor.onaudioprocess = null; // Remove callback
            processor = null;
        }

        // 3. Stop Media Stream
        if (source) { source.disconnect(); source = null; }
        if (stream) { stream.getTracks().forEach(t => t.stop()); stream = null; }

        // 4. Close Session
        if (session) {
             try {
                 console.log("Closing session...");
                 if(session.close) await session.close();
             } catch(e){
                 console.warn("Error closing session:", e);
             }
             session = null;
        }

        // 5. Close Audio Context
        if (audioContext) {
            try { await audioContext.close(); } catch(e){}
            audioContext = null;
        }
    }

    function updateUIState(connected) {
        const btn = document.getElementById('mic-btn');
        const statusText = document.getElementById('status-text');
        const statusInd = document.getElementById('status-indicator');

        btn.disabled = false;
        if (connected) {
            btn.classList.add('listening');
            btn.innerHTML = '<i class="bi bi-stop-fill"></i>';
            statusText.innerText = "Eshitilmoqda...";
            statusInd.className = "badge bg-success";
            statusInd.innerText = "ONLINE";
        } else {
            btn.classList.remove('listening');
            btn.innerHTML = '<i class="bi bi-mic-fill"></i>';
            statusText.innerText = "Darsni Boshlash";
            statusInd.className = "badge bg-secondary";
            statusInd.innerText = "OFFLINE";
        }
    }

    // --- AUDIO HELPERS ---
    function floatTo16BitPCM(input) {
        let output = new Int16Array(input.length);
        for (let i = 0; i < input.length; i++) {
            let s = Math.max(-1, Math.min(1, input[i]));
            output[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }
        // Convert to Base64
        const bytes = new Uint8Array(output.buffer);
        let binary = '';
        for (let i = 0; i < bytes.byteLength; i++) {
            binary += String.fromCharCode(bytes[i]);
        }
        return btoa(binary);
    }

    function base64ToArrayBuffer(base64) {
        const binaryString = atob(base64);
        const bytes = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
            bytes[i] = binaryString.charCodeAt(i);
        }
        return bytes.buffer;
    }

    // --- VISUALIZER ---
    function visualizeAudio(isActive) {
        const canvas = document.getElementById("visualizer");
        if (!canvas) return;
        const ctx = canvas.getContext("2d");
        const width = canvas.width;
        const height = canvas.height;

        ctx.clearRect(0, 0, width, height);
        if (!isActive) return;

        // Simple Random Bars for now
        ctx.fillStyle = "#ff6b81";
        const barWidth = 5;
        const gap = 2;
        const bars = Math.floor(width / (barWidth + gap));

        for (let i = 0; i < bars; i++) {
            const h = Math.random() * height * 0.8;
            const x = i * (barWidth + gap);
            const y = (height - h) / 2;
            ctx.fillRect(x, y, barWidth, h);
        }

        if(isConnected) {
            requestAnimationFrame(() => visualizeAudio(true));
        }
    }

    // --- INIT ---
    renderUI();
</script>
{% endblock %}
